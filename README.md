# deep-learning

В ДЗ4 на собственном горьком опыте убедилась в том, что BERT - очень медленная и прожорливая в смысле памяти штука. 

Изначально пыталась как в статье для imdb делать, но это совершенно убийственно, поменяла датасет на смски, т.к. они маленькие и для классификации на 2 класса можно сделать датасет поменьше, а это очень критично было, т.к. компьютер именно по памяти умирал.

В результате минимизировала размер batch и количество слов

В общем, довольно приключенческая домашка вышла